\documentclass[a4paper,12 pt]{article}
\usepackage{geometry}
\geometry{letterpaper, margin=0.8in}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{enumitem}
\setlist{  
  listparindent=\parindent,
  parsep=0pt,
}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{float}
\usepackage{amssymb}
\usepackage{bbm}
\usepackage[normalem]{ulem}
\usepackage{natbib}
\usepackage{listings}


\title{\vspace{-2.0cm}CSCI 6360: Parallel Computing Lecture Summary - 17}
\author{Anirban Das (dasa2@rpi.edu) }
\date{March 27, 2018}


\begin{document}
\maketitle

\paragraph{Summary on Lecture 17\\\\}

Ring is bad. All memory is cache. Figure 1.YOu could go across rings to the neighbours. Ring of ring architecture and can have a max capacity of 32 gb or ram. Describe the architecture of the ring.

The other part is the way memory is analysed. All memory was cached so on your 64 bit 25mhz sparc like processor, if the amount of data shared to you is 32mb, then like all caches you evict old stuff and use new keep new stuff like LRU fashio. Here in this architecture where do we spill to? We spill data to the neighbour. Shouldnt have memory sharing more than the size of the cache. Need to create processor specific pool of memory. 

Performance. whats the effect of placement of processing threads. The workload performing steps (7 of them). They are trying to get rid of interrupts that might cause problems. Figure 2. two if the rings in this case.

Fig 3. They are looking at ring a and b. and Fig 3. when owners are at cell no. 31, then they see quicker response time. Turned out one problem is request goes around on one way but the response is on th other way. SO upto 31 the performance is high, then you go to the second ring and the access time is quicker. While the request went around the data request is much quicker and doesnot haveto move all way aroun the ring????

Interesting thing is reader writers and suites no body ever done anything which says heres the linpack or any mordern benchmark but only did generic reader writer performance. No real piece of software running , drawback.



Intel phi, ALSO RING. Whats the difference? slight change in memory some generations etc but not much more. Old ring comeback on a single chip.L1 is similar to first level cache and shared L2. Thread style programming model. Two modes you can run the phi in native execution mode with its own OS etc and offload mode when you can offload parts of the application on to the card itself. Sort of like a mesh like network wih then memory banks closest to the procesors with the BCS infiniband type of node. 

First question is what sort of memory bandwidth we will get . Is it any thread accessing any memory or is it balanced??????? Figure 3. They have real benchmarks. Parallel for overheadaa dns what are th cost%sub.


BCS, RIng architectures. 

Intel Knights landing in the new cray processors and this can work as a host processor. Memory bw is lower and if you have an application that uses a terabyte of ram then you cant use this need a xeon. Tiled mesh or 2d torus processor. Optics directly on the chip, silicon photonics













































\end{document}